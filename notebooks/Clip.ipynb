{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a41f33-edc3-4f0a-acc5-7cf75d4e6b83",
   "metadata": {},
   "source": [
    "# CLIP for selection suggestions\n",
    "\n",
    "CLIP is a model for comparing natural language with images. In this notebook, I want to check if it can be used as part of our selection UI. This is a qualitative study.\n",
    "\n",
    "The CLIP model outputs embeddings (e_text, e_image) for a (text, image) pair. The dot product between the e_text and e_image is the similarity score. For a given text prompt and a graphic, I'll show the best node in the graphic's tree. I'll start out with ground truth annotations for graphics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c63e1-dd12-4733-ae69-ceb943f9cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorrvnn.utils import *\n",
    "from vectorrvnn.data import *\n",
    "from vectorrvnn.utils import *\n",
    "from vectorrvnn.baselines import *\n",
    "from vectorrvnn.trainutils import *\n",
    "from vectorrvnn.interfaces import *\n",
    "\n",
    "opts = Options().parse(testing=[\n",
    "    '--backbone', 'resnet18',\n",
    "    '--checkpoints_dir', '../results',\n",
    "    '--dataroot', '../data/All',\n",
    "    '--embedding_size', '64',\n",
    "    '--hidden_size', '128', '128',\n",
    "    '--load_ckpt', 'expt1/training_end.pth',\n",
    "    '--loss', 'cosineSimilarity',\n",
    "    '--modelcls', 'ThreeBranch',\n",
    "    '--name', 'test',\n",
    "    '--sim_criteria', 'negativeCosineSimilarity',\n",
    "    '--device', 'cuda:0',\n",
    "    '--phase', 'test',\n",
    "    '--temperature', '0.1',\n",
    "    '--use_layer_norm', 'true',\n",
    "    '--seed', '0',\n",
    "])\n",
    "setSeed(opts)\n",
    "_, _, _, _, data = buildData(opts)\n",
    "grouper = buildModel(opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242a294-01a2-4169-b39f-05c9d2b36a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/PublicDomainVectors'\n",
    "\n",
    "svgFiles = [f for f in allfiles(DATA_DIR) if f.endswith('svg')][:800]\n",
    "publicDomain  = [SVGData(_) for _ in svgFiles]\n",
    "# Filter out graphics with too many paths. \n",
    "publicDomain = [_ for _ in publicDomain if _.nPaths < 40] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f5161-98b5-433e-b0ff-5e88d6c00738",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model = model.float()\n",
    "\n",
    "def matchingNode (text, tree) :\n",
    "    pp_text = clip.tokenize([text]).to(device)\n",
    "    pathSets = [tree.nodes[n]['pathSet'] for n in tree.nodes]\n",
    "    subdocs = [subsetSvg(tree.doc, ps) for ps in pathSets]\n",
    "    rasters = [rasterize(sd, 256, 256) for sd in subdocs]\n",
    "    bit8 = [(n * 255).astype(np.uint8) for n in rasters]\n",
    "    images = [Image.fromarray(b, 'RGBA') for b in bit8]\n",
    "    pp_image = torch.stack([preprocess(im) for im in images]).to(device)\n",
    "    with torch.no_grad() : \n",
    "        logits_per_image, _ = model(pp_image, pp_text)\n",
    "        probs = logits_per_image.softmax(dim=0).cpu().numpy()\n",
    "        probs = probs.reshape(-1)\n",
    "    top3 = probs.argsort()[-3:][::-1]\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    print(\"Showing top 3 matches for prompt -\", text)\n",
    "    for i, ax in enumerate(axes) : \n",
    "        ax.imshow(bit8[top3[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2e619-2f74-4a5c-ad74-1a618cf4fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataId = 203\n",
    "\n",
    "print(\"Showing whole graphic\")\n",
    "plt.imshow(rasterize(publicDomain[dataId].doc, 256, 256))\n",
    "plt.show()\n",
    "matchingNode(\"The polar bear's head\", grouper.containmentGuidedTree(publicDomain[dataId]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a382c-57cd-47ab-8192-1374efbfaf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
