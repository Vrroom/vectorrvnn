{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04a5ce7-e99d-4be7-9f4c-3fd0fe3c8c92",
   "metadata": {},
   "source": [
    "# Automatically detecting strokes and fills\n",
    "\n",
    "A lot of times, for whatever reason, the strokes and fills are separated out. I think the stroke and fill for a shape can be easily detected from the geometry and I'm vary of asking annotators to give us this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a2d86-d68c-4e82-8a6e-d2de87cd4193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vectorrvnn.utils import *\n",
    "from vectorrvnn.geometry import *\n",
    "from vectorrvnn.data import *\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import KDTree\n",
    "    \n",
    "svgfiles = list(filter(lambda x : x.endswith('svg'), allfiles('../Emojis')))[100:101]\n",
    "trees = [SVGData(f) for f in svgfiles]\n",
    "for tree in tqdm(trees): \n",
    "    plt.imshow(rasterize(tree.doc, 200, 200))\n",
    "    plt.show()\n",
    "    for g in maximalCliques(tree, [fourier_descriptor, centroid], 1e-2):\n",
    "        plt.imshow(rasterize(subsetSvg(tree.doc, g), 100, 100))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e17ef-187c-4754-8b60-68be62aaa31e",
   "metadata": {},
   "source": [
    "The first cut worked well when the stroke and fills completely matched. It didn't work out in cases such as the one above. The two shapes are only slightly different. Fourier descriptor doesn't think so. So now I'm going to try shape contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758dfc5f-c0a2-4a26-966c-c174b21d9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=100)\n",
    "def shapeContexts (doc, i, nSamples=100) : \n",
    "    \"\"\" Give a list of shape contexts that can be used for matching \"\"\"\n",
    "    path = cachedPaths(doc)[i].path\n",
    "    pts = np.array(equiDistantSamples(doc, path, nSamples, normalize=True)).T\n",
    "    grid = pts.reshape((-1, 1, 2))\n",
    "    grid = np.repeat(grid, nSamples, axis=1)\n",
    "    diffs = grid - pts\n",
    "    mask = np.eye(nSamples).astype(bool)\n",
    "    diffs = diffs[~mask].reshape(nSamples, nSamples - 1, 2)  \n",
    "    logNorms = np.log2(np.linalg.norm(diffs, axis=2) + 1e-7)\n",
    "    thetas = np.arctan2(diffs[:, :, 0], diffs[:, :, 1])\n",
    "    xbins = np.linspace(-10, 0.5, 10)\n",
    "    ybins = np.linspace(-np.pi, np.pi, 10)\n",
    "    contexts = []\n",
    "    # Figure out how to vectorize this step.\n",
    "    for i in range(nSamples) : \n",
    "        H, *_ = np.histogram2d(logNorms[i], thetas[i], bins=[xbins, ybins], density=True)\n",
    "        contexts.append(H)\n",
    "    return contexts\n",
    "\n",
    "@lru_cache(maxsize=100)\n",
    "def error2 (doc, i, j, nSamples=100) :\n",
    "    def chi2 (c1, c2) : \n",
    "        return (0.5 * (c1 - c2) ** 2 / (c1 + c2 + 1e-5)).sum()\n",
    "    cn1, cn2 = centroid(doc, i), centroid(doc, j)\n",
    "    ctx1 = shapeContexts(doc, i, nSamples)\n",
    "    ctx2 = shapeContexts(doc, j, nSamples) \n",
    "    costDict = dict()\n",
    "    for (i, ci), (j, cj) in product(enumerate(ctx1), enumerate(ctx2)) : \n",
    "        costDict[(i, j)] = chi2(ci, cj)\n",
    "    matching = optimalBipartiteMatching(costDict)\n",
    "    costs = []\n",
    "    for i, j in matching.items() : \n",
    "        costs.append(costDict[(i, j)])\n",
    "    err = np.median(costs) + np.linalg.norm(cn1 - cn2)\n",
    "    return err\n",
    "\n",
    "# for g in maximalCliques(doc, error2, 2e-1): \n",
    "#     print(g)\n",
    "#     plt.imshow(rasterize(subsetSvg(doc, g), 100, 100))\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
