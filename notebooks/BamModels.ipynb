{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore BAM! Dataset and Models\n",
    "\n",
    "I want to do the following:\n",
    "\n",
    "1. Find the class distribution.\n",
    "2. Load some suggero examples.\n",
    "3. Run the latest BAM! Model from results on them and see if predictions match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osTools import *\n",
    "from listOps import *\n",
    "from PIL import Image\n",
    "from more_itertools import *\n",
    "import sys\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "BAM_H5 = '/misc/extra/data/sumitc/bam.h5'\n",
    "BAM_DIR = '/misc/extra/data/sumitc/bam'\n",
    "\n",
    "classNames = list(map(getBaseName, listdir(BAM_DIR)))\n",
    "\n",
    "with h5py.File(BAM_H5, 'r') as hf : \n",
    "    labels = hf.get('labels')[()]\n",
    "print('BAM! Dataset Size -', labels.shape[0])\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, _ = np.histogram(labels, bins=len(classNames))\n",
    "plt.pie(hist, labels=classNames, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TripletDataset import *\n",
    "\n",
    "SUGGERO_DIR = '/misc/extra/data/sumitc/suggero/train'\n",
    "\n",
    "dataset = TripletSVGDataSet(SUGGERO_DIR)\n",
    "print('Suggero Dataset -', len(dataset.svgDatas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from treeOps import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "dataPts = list(zip(dataset.svgDatas, dataset.files))\n",
    "samples = random.sample(dataPts, k=100)\n",
    "imgs = [] \n",
    "testTransform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "for t, f in samples: \n",
    "    r = findRoot(t)\n",
    "    im = np.array(dataset.loadImage(f, 'whole', r))\n",
    "    imgs.append(im)\n",
    "    \n",
    "for i in range(20) : \n",
    "    plt.imshow(np.concatenate(imgs[5 * i: 5 * (i + 1)], axis=1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model And Test\n",
    "from torchvision.models import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(''))\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'vectorrvnn', 'results', 'bam_aug2')\n",
    "model = resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 20)\n",
    "state_dict = torch.load(os.path.join(MODEL_DIR, \"epoch_15.pth\"))\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model = model.float()\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "modelInput = torch.stack([testTransform(image=im)['image'] for im in imgs]).cuda()\n",
    "with torch.no_grad() : \n",
    "    scores = model(modelInput)\n",
    "probabilities = torch.nn.functional.softmax(scores, dim=0)\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5, dim=1)\n",
    "\n",
    "for i, im in enumerate(imgs) : \n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    for j in range(5) : \n",
    "        print(classNames[top5_catid[i][j]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test elements of the Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Triplet import *\n",
    "\n",
    "with open('./commonConfig.json') as fd : \n",
    "        config = json.load(fd)\n",
    "valData = TripletSVGDataSet(osp.join(config['suggero_dest'], 'val'))\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    valData, \n",
    "    batch_size=128, \n",
    "    sampler=TripletSampler(valData.svgDatas, 25600, True),\n",
    "    pin_memory=True,\n",
    "    num_workers=6,\n",
    "    collate_fn=lambda x : aggregateDict(x, torch.stack)\n",
    ")\n",
    "# Initiate main model.\n",
    "model = TripletNet(dict(hidden_size=100)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PositionalEncoding import *\n",
    "\n",
    "for batch in val_dataloader : \n",
    "    break\n",
    "\n",
    "pe = PositionalEncoding()\n",
    "pe.to(\"cuda\")\n",
    "nodeWhole = batch['refWhole'].cuda()\n",
    "positions = batch['refPositions'].cuda()\n",
    "vis = (nodeWhole - nodeWhole.min()) / (nodeWhole.max() - nodeWhole.min())\n",
    "vis = vis.permute((0, 2, 3, 1)).detach().cpu().numpy()\n",
    "# Checking Input\n",
    "for i in range(0, vis.shape[0], 32) : \n",
    "    plt.imshow(vis[i])\n",
    "    plt.show()\n",
    "\n",
    "x = model.conv(nodeWhole)\n",
    "x_ = pe(x, positions)\n",
    "\n",
    "print('Norms -', torch.linalg.norm(x_ - x).item(), torch.linalg.norm(x).item())\n",
    "\n",
    "encoding = pe.pe.squeeze().detach().cpu().numpy()\n",
    "plt.imshow(encoding)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
